---
title: "An Evidence-based Forecast: Gold as a Traditional Safe-Haven Investment"
author: "Yuqiao Yang"

execute:
  echo: false
  
bibliography: references.bib
---

> **Abstract.** This research aims to explore future trends in Gold prices as a traditonal safe-haven investment using a Bayesian VARs model. In the wake of the 2008 financial crisis and especially the 2019 global Covid-19 pandemic, the world economy appears to be on the brink of a looming risk: a world-wide economic recession. The concern over the risk of investment returns has become a primary focus for global investors and financial institutions. This unease has been further exacerbated by geopolitical conflicts such as the Russia-Ukraine war (2022) and the Israeli-Palestinian conflict (2023). Consequently, this research aims to provide a briefly discussion and data-driven forecast of traditional safe-haven assets: Gold, under current circumstances. Factors considered include emerging safe-haven investments, risk-free investment assets, comparable investments, market returns, inflation on both demand and supply sides, broad money supply (M2), interest rates, unemployment rates and market volatility.
>
> **Keywords.** Bayesian VARs, Gold price, Inflation, Interset rate, Unemployments, US Bond Yeild, Safe-haven Assets, Forecasting, Volatility, R, Quarto.

# Introduction

**Objective:**

This research project aims to provide a monthly based, data-driven forecast of Gold price(USD) in two years, utilizing a Bayesian VARs model.

**Question:**

Gold as a traditional safe-haven asset, what are the anticipated price movements for the next year or beyond within the current environment?

**Introduction:**

Ulrich Beck introduced the concept of the risk society in the late 20th century, highlighting how humans confront entirely different systemic risks and face challenges in risk allocation under industrial society. Concurrently, globalization has reshaped the world and transformed human perceptions and experiences. Increasingly, evidence suggests that humanity is entering the risk society as described by Beck. Globalization encompasses not only economic, finance, technologe, and culture, but also risks. A China's financial exchange restriction might influence Australia's housing prices, while decisions made by the U.S. Central Bank regarding interest rates can prompt Western central banks to follow suit simultaneously. Following the 2008 financial crisis, major economies mitigated its aftermath significantly through quantitative easing monetary policies. This injection of substantial liquidity propelled economic growth steadily, leading to unprecedented prosperity in specific industries. However, the limitations of quantitative easing became apparent as the Covid-19 pandemic drew to a close. The United States and Western countries experienced unprecedented hyperinflation, coupled with indicators such as rising unemployment rates inversely correlated with inflation, conflicting long-term government bond yields with short-term treasuries, and record-breaking composite indices, signaling an impending global recession.

Geopolitical conflicts, such as the Russia-Ukraine war and the Israeli-Palestinian conflict, have intensified various risks. Disruptions in oil supply, blockages in key waterways, and logistical challenges in transporting goods and agricultural products have further exacerbated commodity price hikes and inflationary pressures. Consequently, mitigating or hedging investment risks has become the primary focus for global investors and financial institutions.

Among various safe-haven investments, gold has regained popularity as a hedge against uncertainty. This research aims to provide investors with a data-supported prediction of gold price trends over the next two years using Bayesian VAR models. The study incorporates information on comparable and emerging hedging products, market risks, returns, unemployment rates, inflation, interest rates, and other relevant parameters to construct a robust Bayesian VAR model. Ultimately, this research aids investors in identifying gold price trends and confidence intervals under different uncertainties within the current environment, thereby mitigating investment risks effectively.

# Data and Data Properties

To enhance the accuracy of gold price predictions, a total selection of 17 variables has been chosen, encompassing gold competitors, risk-free assets, gold futures, and the Nasdaq index. From a broader macroeconomic standpoint, the variables also include inflation, the Producer Price Index (PPI), unemployment rates, crude oil prices, volatility indices, the dollar index, changes in the M2 money supply level, and federal fund effective rates.

-   $GoldETF_{t}$: Gold current price in USD per 0.1 ounce, present by SPDR Gold Shares (GLD), which minus management fees.

-   Competitors and Substitutes for Gold ：

    -   $GoldFutures_{t}$ : Gold future price in USD per ounce, as considering the expectations in further gold price movements and high liquidity safe haven currency than real product.
    -   $BITUSD_{t}$ : As an emerging investment product, with the concept of decentralization, it has become a risk-averse investment product for many investors and financial institutions.
    -   Risk-free assets: treasury bonds
        -   $13WeekNotes_{t}$ : Considering as short-term risk free assets return. More time using in short term risk hedging in portfolio.
        -   $Tbill(5Year)_{t}$ : Considering as mid-term risk free assets return.
        -   $Tbill(10Year)_{t}$ : Considering as mid-term risk free assets return.
        -   $Tbill(30Year)_{t}$ : Considering as long-term risk free assets return.

-   Market returns as opposed to safe-haven investments：

    -   $NasdaqIndex_{t}$ ：Index that include all stocks available in NASDAQ to present the market returns.

-   Macro environment：

    -   $M2_{t}$ : the Board money supply of United States cause price index goes up.
    -   $Infla_{t}$ : CPI Index that present whole price level changes of all goods and services in US. Gold price are highly correlated with inflation.
    -   $Unemp_{t}$ : unemployment rate provide by Bureau of Statistic of US to present a general environment of Labor market.
    -   $CrudeOil_{t}$ : to present as basic cost of production.
    -   $PPI(industry)_{t}$ : to present production side inflation of increase in cost in percentage.
    -   $PPI(commodity)_{t}$ : to present production side inflation of increase in cost in percentage.
    -   $FFERs_{t}$ : As the Federal Funds Effective Rates aim to lower the inflation, decrease the M2 level.
    -   $USDIndex_{t}$ : to present as the purchasing power of USD cross world-wide. That increase the total amount of investors and financial institutions come into US market to earn higher returns.
    -   $VolatilityIndex_{t}$ : to present the risk cross whole market and expectations of further coming events.
    
```{r global options}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

```{r Library}
library(readabs)
library(fredr)
library(blscrapeR)
library(readrba)
library(xts)
library(fUnitRoots)   # ADF test - adfTest
library(tidyverse)    # for table
library(kableExtra)   # for print table
library(dplyr)
library(corrplot)
library(tseries) # for adf test
library(GIGrvg)
set.seed(123)#set random seed for test
```

```{r}
# 1.Gold current price in USD per 0.1 ounce, present by SPDR Gold Shares (GLD)
goldETF_link = "https://query1.finance.yahoo.com/v7/finance/download/GLD?period1=1199232000&period2=1712016000&interval=1mo&events=history&includeAdjustedClose=true"
goldETF_download = read.csv(goldETF_link)
names(goldETF_download) <- tolower(names(goldETF_download))
gold_ETF_data <- goldETF_download %>%
  select("date","gold_ETF_data" = "adj.close")

# 2. Gold futures price in USD per ounce
gold_link = "https://query1.finance.yahoo.com/v7/finance/download/GC%3DF?period1=1009843200&period2=1703980800&interval=1mo&filter=history&frequency=1mo&includeAdjustedClose=true"
gold_download = read.csv(gold_link)
names(gold_download) <- tolower(names(gold_download))
gold_future_data <- gold_download %>%
  select("date","gold_future_data" = "adj.close")

# 3. BIT - USD
BIT_USD = "https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=1410912000&period2=1712102400&interval=1mo&events=history&includeAdjustedClose=true"
BIT_USD_file = read.csv(BIT_USD)
names(BIT_USD_file) <- tolower(names(BIT_USD_file))
BIT_USD_data <- BIT_USD_file %>%
  select("date","BIT_USD_data" = "adj.close")

# 4. 13 Weeks treasury bond yield
bond_yield_13weeks = "https://query1.finance.yahoo.com/v7/finance/download/%5EIRX?period1=-315360000&period2=1712102400&interval=1mo&events=history&includeAdjustedClose=true"
bond_yield_13weeks_file = read.csv(bond_yield_13weeks)
names(bond_yield_13weeks_file) <- tolower(names(bond_yield_13weeks_file))
bond_yield_13weeks_data <- bond_yield_13weeks_file %>%
  select("date","bond_yield_13weeks_data" = "adj.close")

# 5. 5-Year treasury bond yield
bond_yield_5years = "https://query1.finance.yahoo.com/v7/finance/download/%5EFVX?period1=-252374400&period2=1712016000&interval=1mo&events=history&includeAdjustedClose=true"
bond_yield_5years_file = read.csv(bond_yield_5years)
names(bond_yield_5years_file) <- tolower(names(bond_yield_5years_file))
bond_yield_5years_data <- bond_yield_5years_file %>%
  select("date","bond_yield_5years_data" = "adj.close")

# 6. 10-Year treasury bond yield
bond_yield_10years = "https://query1.finance.yahoo.com/v7/finance/download/%5ETNX?period1=-252374400&period2=1712016000&interval=1mo&events=history&includeAdjustedClose=true"
bond_yield_10_years = read.csv(bond_yield_10years)
names(bond_yield_10_years) <- tolower(names(bond_yield_10_years))
bond_yield_10_years_data <- bond_yield_10_years %>%
  select("date","bond_yield_10_years_data" = "adj.close")

# 7. 30-Year treasury bond yield
bond_yield_30years = "https://query1.finance.yahoo.com/v7/finance/download/%5ETYX?period1=224812800&period2=1712102400&interval=1mo&events=history&includeAdjustedClose=true"
bond_yield_30years_file = read.csv(bond_yield_30years)
names(bond_yield_30years_file) <- tolower(names(bond_yield_30years_file))
bond_yield_30years_data <- bond_yield_30years_file %>%
  select("date","bond_yield_30years_data" = "adj.close")

# 8. Nasdaq Index
Nasdaq_IXIC = "https://query1.finance.yahoo.com/v7/finance/download/%5EIXIC?period1=34646400&period2=1712102400&interval=1mo&events=history&includeAdjustedClose=true"
Nasdaq_IXIC_file = read.csv(Nasdaq_IXIC)
names(Nasdaq_IXIC_file) <- tolower(names(Nasdaq_IXIC_file))
Nasdaq_IXIC_data <- Nasdaq_IXIC_file %>%
  select("date","Nasdaq_IXIC_data" = "adj.close")

# 9. M2 level
M2_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=WM2NS&scale=left&cosd=1980-11-03&coed=2024-03-04&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=eop&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=pch&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1980-11-03"
M2_rate_file = read.csv(M2_rate)
names(M2_rate_file) <- tolower(names(M2_rate_file))
M2_rate_data <- M2_rate_file %>%
  select("date","M2_rate_data" = "wm2ns_pch")

# 10. Inflation rate
Inflation_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=CPIAUCSL&scale=left&cosd=1947-01-01&coed=2024-02-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=eop&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=pch&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1947-01-01"
Inflation_rate_file = read.csv(Inflation_rate)
names(Inflation_rate_file) <- tolower(names(Inflation_rate_file))
Inflation_rate_data <- Inflation_rate_file %>%
  select("date","Inflation_rate_data" = "cpiaucsl_pch")

# 11. Unemployment rate
unemployment_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=UNRATE&scale=left&cosd=1948-01-01&coed=2024-02-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-04-02&revision_date=2024-04-02&nd=1948-01-01"
unemployment_rate_file = read.csv(unemployment_rate)
names(unemployment_rate_file) <- tolower(names(unemployment_rate_file))
unemployment_rate_data <- unemployment_rate_file %>%
  select("date","unemployment_rate_data" = "unrate")

# 12. Crude oil price
Crude_oil_price = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=off&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=DCOILBRENTEU&scale=left&cosd=1990-01-01&coed=2024-03-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=eop&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1987-05-20"
Crude_oil_price_file = read.csv(Crude_oil_price)
names(Crude_oil_price_file) <- tolower(names(Crude_oil_price_file))
Crude_oil_price_data <- Crude_oil_price_file %>%
  select("date","Crude_oil_price_data" = "dcoilbrenteu")

# 13. PPI - Industry
PPI_industry_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=PCUOMFGOMFG&scale=left&cosd=1984-12-01&coed=2024-02-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=pch&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1984-12-01"
PPI_industry_rate_file = read.csv(PPI_industry_rate)
names(PPI_industry_rate_file) <- tolower(names(PPI_industry_rate_file))
PPI_industry_rate_data <- PPI_industry_rate_file %>%
  select("date","PPI_industry_rate_data" = "pcuomfgomfg_pch")

# 14. PPI - Commodity
PPI_commodity_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=PPIACO&scale=left&cosd=1913-01-01&coed=2024-02-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=pch&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1913-01-01"
PPI_commodity_rate_file = read.csv(PPI_commodity_rate)
names(PPI_commodity_rate_file) <- tolower(names(PPI_commodity_rate_file))
PPI_commodity_rate_data <- PPI_commodity_rate_file %>%
  select("date","PPI_commodity_rate_data" = "ppiaco_pch")

# 15. Federal Funds Effective Rates
Federal_funds_rate = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=FEDFUNDS&scale=left&cosd=1990-01-01&coed=2024-03-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1954-07-01"
Federal_funds_rate_file = read.csv(Federal_funds_rate)
names(Federal_funds_rate_file) <- tolower(names(Federal_funds_rate_file))
Federal_funds_rate_data <- Federal_funds_rate_file %>%
  select("date","Federal_funds_rate_data" = "fedfunds")

# 16. US dollars Index
US_dollars_Index = "https://query1.finance.yahoo.com/v7/finance/download/DX-Y.NYB?period1=31795200&period2=1712102400&interval=1mo&events=history&includeAdjustedClose=true"
US_dollars_Index_file = read.csv(US_dollars_Index)
names(US_dollars_Index_file) <- tolower(names(US_dollars_Index_file))
US_dollars_Index_data <- US_dollars_Index_file %>%
  select("date","US_dollars_Index_data" = "adj.close")

# 17. Volatility Index
Volatility_Index = "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=VIXCLS&scale=left&cosd=1990-01-02&coed=2024-03-01&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Monthly&fam=eop&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-04-03&revision_date=2024-04-03&nd=1990-01-02"
Volatility_Index_file = read.csv(Volatility_Index)
names(Volatility_Index_file) <- tolower(names(Volatility_Index_file))
Volatility_Index_data <- Volatility_Index_file %>%
  select("date","Volatility_Index_data" = "vixcls")

```


```{r}
data_list <-    list(gold_ETF_data,           gold_future_data, 
                     BIT_USD_data,            bond_yield_13weeks_data, 
                     bond_yield_5years_data,  bond_yield_10_years_data,  
                     bond_yield_30years_data, Nasdaq_IXIC_data, 
                     M2_rate_data,            Inflation_rate_data,
                     unemployment_rate_data,  Crude_oil_price_data,
                     PPI_industry_rate_data,  PPI_commodity_rate_data,
                     Federal_funds_rate_data, US_dollars_Index_data,
                     Volatility_Index_data)  


merged_data <- Reduce(function(x, y) merge(x, y, by = "date", all = TRUE), data_list)


start_date <- as.Date("2014-01-01")
end_date <- as.Date("2024-04-01")
filtered_data <- merged_data %>%
  filter(date >= start_date & date <= end_date)

filtered_data <- na.omit(filtered_data)

```

After download all variables as designed, merge all data sets into a new frame and change the column names. The date of data used in this research will start at 2014-10-01 as at 2024-04-01.

# Plots of all variables

```{r}
data1 <- subset(filtered_data, select = -c(date))

data1 <- mutate_all(data1, as.numeric)

par(mfrow = c(4, 4), mar=c(2,2,2,2))
for (i in 1:17) { 
  ts.plot(data1[, i], main = colnames(data1)[i], 
          ylab = "", xlab = "")
}


```

As above, we could have all 17 variables in visualization format individually. As a quick overlook, 13 weeks bond has a similar trend with federal funds effective rates; other 3 treasury bonds move quite same; gold and its' future, Nasdaq, Bit coin, crude oil price and US dollars Index have upper ward trends; Unemployment rates seems like opposite to federal rates; M2 and other 3 time series seems like stationary on mean but variance change over time.

**Correlation Table**

```{r}
correlation_matrix <- cor(data1)

corrplot(correlation_matrix, method = "color", type = "upper", tl.srt = 45,tl.col = "black",tl.cex = 0.5)
```
A simple correlation provide us a basic understanding of those 17 variables. Gold as safe-haven is highly positive correlated with Gold future and Nasdaq Index. Seems like its also a strong bond between Bit coin and Gold, however other factors not shown as strong correlation with Gold price.

Therefore, we could use ACF and PACF test to indicate whether there is autocorrelations.

```{r}
par(mfrow = c(4, 4), mar=c(2,2,2,2))
for (i in 1:17){
acf = acf(data1[,i], plot = FALSE)[1:20]
plot(acf, main = "")
title(main = paste(colnames(data1)[i]), line = 0.5)
}

par(mfrow = c(4, 4), mar=c(2,2,2,2))
for (i in 1:17){
pacf = pacf(data1[,i], plot = FALSE)[1:20]
plot(pacf, main = "")
title(main = paste(colnames(data1)[i]), line = 0.5)
}
```

Both ACF and PACF suggest that variables are highly autocorrelated except M2: Board money change rate. That might because the policy has changed in earlier 2020 and 2022. Therefore, we further need ADF test(unit root test) to feed our time series are stationary or not.

```{r}

adf_test <- list()
for (i in 1:17) {
  adf_result = adf.test(data1[,i], k = 4)
  adf_test[[i]] <- adf_result
}
adf_table <- data.frame(p_value = numeric(length(adf_test)))
adf_table <- data.frame(p_value = numeric(length(adf_test)))
for (i in 1:length(adf_test)) {adf_table[i, "p_value"] = round(adf_test[[i]]$p.value,3)
}

rownames(adf_table)<- c("gold_ETF_data",           "gold_future_data", 
                     "BIT_USD_data",            "bond_yield_13weeks_data", 
                     "bond_yield_5years_data",  "bond_yield_10_years_data",  
                     "bond_yield_30years_data", "Nasdaq_IXIC_data", 
                     "M2_rate_data",            "Inflation_rate_data",
                    "unemployment_rate_data",  "Crude_oil_price_data",
                     "PPI_industry_rate_data",  "PPI_commodity_rate_data",
                     "Federal_funds_rate_data", "US_dollars_Index_data",
                     "Volatility_Index_data")
colnames(adf_table)<- c("P-value")
knitr::kable(adf_table)
```


# Modeling and Hypothesis

This research project based on **Bayesian VARs(p) model** to forecast the Gold price in next two years. For time $t$ = {1,2,3,...,$T-1$,$T$} :

```{=tex}
\begin{aligned}
y_t &= \mu_0 + A_1y_{t-1} + A_2y_{t-2}...+A_py_{t-p} +\epsilon_t\\

\epsilon_t|Y_{t-1} &\sim iid \mathcal{N}_{17}(0_{17}, \Sigma)
\end{aligned}
```

Where N = 17 and $y_{t}$ is a vector of 17 variables at time $t$.

```{=tex}
\begin{aligned}

y_{t}=\begin{pmatrix}
GoldETF_{t} \\
GoldFutures_{t}\\
BITUSD_{t} \\
13WeekNotes_{t}\\
Treasurybill(5Year)_{t} \\
Treasurybill(10Year)_{t} \\
Treasurybill(30Year)_{t} \\
NasdaqIndex_{t} \\
M2_{t} \\
Inflation_{t} \\
Unemployment_{t}\\
CrudeOil_{t}\\
PPI(industry)_{t} \\
PPI(commodity)_{t}\\
FFERs_{t} \\
USDollarIndex_{t}\\
VolatilityIndex_{t}\\
\end{pmatrix}

\end{aligned}
```
For time $t$ = 1,2,.....,$T$：

-   $y_t$ is a $N(17)\times 1$ vector of observations at time $t$
-   $\mu_0$ is a $N(17)\times 1$ vector of constant terms
-   $A_i$ is a $N(17)\times N(17)$ matrix of autoregressive slope parameters
-   $\epsilon_t$ is a $N(17)\times 1$ vector of error terms which is a multivariate white nose process(time invariant)
-   $Y_{t-1}$ is the information set collecting observations on y up to time $t-1$
-   $\Sigma$ is a $N(17)\times N(17)$ covariance matrix of the error term

In matrix notation:

$$
\begin{align}
Y &= X A +E 
\\
E|X &\sim \mathcal{MN}_{T\times N}(\textbf{0},\Sigma,I_T)
\\
Y|X &\sim \mathcal{MN}_{T\times N}(XA,\Sigma,I_T)
\end{align} 
$$ 

```{=tex}
\begin{aligned}

A=
\begin{bmatrix}
\mu_{0}' \\ A_{1}' \\
A_{2} '\\.\\.\\.\\A_{p}'
\end{bmatrix}_{K \times N}

Y=
\begin{bmatrix}
y_{1}' \\ y_{2}' \\
y_{3} '\\.\\.\\.\\y_{T}'
\end{bmatrix}_{T \times N}

x_t=
\begin{bmatrix}
1 \\ y_{t-1}' \\
y_{t-2} '\\.\\.\\.\\y_{t-p}'
\end{bmatrix}_{K \times 1}

X=
\begin{bmatrix}
x_{1}' \\ x_{2}' \\
x_{3} '\\.\\.\\.\\x_{T}'
\end{bmatrix}_{T \times K}

E=
\begin{bmatrix}
\epsilon_1' \\ \epsilon_2' \\
\epsilon_3 '\\.\\.\\.\\\epsilon_T'
\end{bmatrix}_{T \times N}

\end{aligned}
```

where K = 1 + pN

Base on the model above, we could first turn B Vars(p) model into B Vars(1) model and easily regress to have the parameter matrix. Then we could have a $t+h$ period forward forecasting with increase of variance, in this case: $h$ = 24.

The main focus of estimate output is the conditional mean of Gold price, which base on current information set $Y_{t-1}$. It provide the average mean prediction of Gold price which investors and financial institutions interested in. Moreover, 1 standard deviation and 2 standard deviation will also produced in forecasting process to provide a 68% and 95% of confidence intervals of future Gold price movements in $h$ periods base on current information set.

Furthermore, different prior distribution might be used to provide different level of uncertainty of current environment(information set). Compare the difference of Gold price under different priors could help to prove the Gold as a high quality safe-haven investment and increase investors and financial institutions confidence and further expectations. ( Competitors for golds might also be used under different priors, such as BIT-USD, Nasdaq Index and short to mid-term treasury bills. )

Based on Bayes' Theorem:

```{=tex}
\begin{aligned}

P(A|B) & =\frac{P(B|A)P(A)}{P(B)} \\
P(A|B) & \propto P(B|A)P(A)

\end{aligned}
```

Therefore we have:

```{=tex}
\begin{aligned}

P(A,\Sigma|Y,X) &= \frac{P(Y|X,A,\Sigma) \ P(A,\Sigma)}{P(Y)}\\
&\propto P(Y|X,A,\Sigma) \ P(A,\Sigma)\\
&= L(A,\Sigma | Y,X) \ P(A|\Sigma) \ P(\Sigma) \\\\

A|\Sigma &\sim \mathcal{MN}_{K\times N}(\underline{A}, \Sigma,\underline{V}) 
\\ 
\Sigma &\sim \mathcal{IW}_{N}(\underline{S}, \underline{v})

\end{aligned}
```

Which is the posterior distribution is the proportion of likelihood function and prior.

where $A_{M \times N}$ follow a matrix normal distribution:
- $\underline{A}$ is the mean of matrix normal distribution
- $\Sigma_{N \times N}$is the row specific covariance matrix
- $\underline{V}_{M \times M}$is the column specific covariance matrix 
therefore, we have:

```{=tex}
\begin{aligned}

vec(A)\sim N_{MN}(vec(\underline{A}),\Sigma\otimes \underline{V})

\end{aligned}
```

where $/Sigma$ follow a Inverse Wishart distribution:
- $\underline{S}$ is N × N positive definite symmetric matrix called the scale matrix 
- $\underline{v}$ > N + 2 denotes degrees of freedom

## First Benchmark Assumption: Basic model with Minnesota prior

In real life, macroeconomic variables are more likely being unit-root non stationary and are well-characterized by a multivariate random walk process

```{=tex}
\begin{aligned}

y_{t} = y_{t-1} + \epsilon_t

\end{aligned}
```

-Therefore, we first use Minnesota prior(1984) for our Bayesian forecasting:

Set the prior mean $A$ to:
```{=tex}
\begin{aligned}

\underline{A}=\left[ 0_{N\times1} \ \ \ \  I_{N} \ \ \ \ \ 0_{N\times(p-1)N} \right]'

\end{aligned}
```

where the mean of first lag equal to 1 and mean of constant term and other lags are 0.

Set the column specific prior covariance of $A$ (prior shrinkage)to:
```{=tex}
\begin{aligned}

\underline{V} = diag\left[ \kappa_{2} \quad \kappa_{1}(\textbf{p} ^{-2}\otimes I^{'}_{N}) \right]

\end{aligned}
```

where:


### Function Proofing

Consider Bi-variate Gaussian random walk process:

$$
y_t = 
\begin{bmatrix}
y_{t,1} \\
y_{t,2}
\end{bmatrix} = 
\begin{bmatrix}
y_{t-1,1} \\
y_{t-1,2}
\end{bmatrix} + 
\begin{bmatrix}
\epsilon_{t,1} \\
\epsilon_{t,2}
\end{bmatrix} 
, where   \  \ 
\epsilon_{t,1} \sim \mathcal{N}(0,1)  \ and \ 
\epsilon_{t,2} \sim \mathcal{N}(0,1)
$$

$$ 
Y = \begin{bmatrix}
y_2' \\
y_3' \\
\vdots \\
y_n'
\end{bmatrix},
\quad
X = \begin{bmatrix}
1 \quad y_1' \\
1 \quad y_2' \\
\vdots \quad \vdots \\
1 \quad y_{n-1}'
\end{bmatrix}
$$


Function below is `posterior.draws`:

```{r Basic Model, fig.align='center',fig.pos='H'}
#| echo: true

## Posterior sample draw function for basic model(posterior.draws)
posterior.draws       = function (S, Y, X){
  
    # normal-inverse Wishard posterior parameters
    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))
    V.bar             = solve(V.bar.inv)
    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
    nu.bar            = nrow(Y) + nu.prior
    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv         = solve(S.bar)
    
    # posterior draws 
    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior   = apply(Sigma.posterior,3,solve)
    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
    L                 = t(chol(V.bar))
    
    for (s in 1:S){
      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    }

    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)
    return(output)
}
```


```{r Basic Model Function Proof, fig.align='center',fig.pos='H'}

e1 = cumsum(rnorm(1000, 0, sd=1))
e2 = cumsum(rnorm(1000, 0, sd=1))
e  = cbind(e1,e2)

## Define data X, Y 
Y = ts(e[2:nrow(e),], frequency=1)
X = matrix(1,nrow(Y),1)
X = cbind(X,e[2:nrow(e)-1,])


## Test on basic model
N           = ncol(Y)                          # N=2
p           = frequency(Y)
A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution (with Minnesota prior)
kappa.1             = 1                                    # shrinkage for A1 to Ap
kappa.2             = 100                                  # shrinkage for constant 
A.prior             = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N + 1),] = diag(N)
V.prior             = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior             = diag(diag(Sigma.hat))
nu.prior            = N+2
# Applying function 
posterior.sample.draws.p = posterior.draws(S=10000, Y=Y, X=X)

```

- The posterior mean of the $A$ is:

```{r Basic Model Proof A, fig.align='center',fig.pos='H'}


basic.model.proof.A <- 
  tibble( "A" = c("Constant term", "Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.sample.draws.p[["A.posterior"]][1,1,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][2,1,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][3,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.sample.draws.p[["A.posterior"]][1,2,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][2,2,]),4),
              round(mean(posterior.sample.draws.p[["A.posterior"]][3,2,]),4))

  )

kable(basic.model.proof.A, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 2 Basic Model Proofing Simulation for $A$

- The posterior mean of the $\Sigma$ is:

```{r Basic Model Proof Sigma, fig.align='center',fig.pos='H'}


basic.model.proof.Sigma <-
  tibble( "Sigma" = c("Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.sample.draws.p[["Sigma.posterior"]][1,1,]),4),
              round(mean(posterior.sample.draws.p[["Sigma.posterior"]][2,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.sample.draws.p[["Sigma.posterior"]][1,2,]),4),
              round(mean(posterior.sample.draws.p[["Sigma.posterior"]][2,2,]),4))

  )

kable(basic.model.proof.Sigma, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 3 Basic Model Proofing Simulation for $\Sigma$

Extension Model:

## The extended model: Laplace distribution of error term

The **Basic Model** is the standard VARs model that assume the error terms $U$ are independent and identically distributed($iid$) as $N\sim (0,\Sigma)$. In other formation, it could be presented as $vec(U)\sim N(0,\Sigma\otimes I_{t})$. Where $\Sigma$ is a $n \times n $ covariance matrix, $I_{t}$ is a $ t \times t$ identity matrix, $\otimes$ is the Kronecker product and the operator $vec(.)$ is vectorization that inverts the matrix into the column vector by stacking the columns.

Therefore, we could consider a more general covariance structure:

```{=tex}
\begin{align}

vec(U)\sim N(0,\Sigma\otimes I_{t})

\end{align}
```


The extended model will be built based on the the change in distribution of the error to **Laplace distribution** instead of the normally distributed errors assumption. The Laplace distribution is suitable for describing financial anomalies due to its sharp peaks and thick tails and the use of this distribution improves the robustness of the model to anomalies and is particularly suitable for financial time series. As our variables are most financial time series data, a Laplace distribution is more suitable to apply to our error term.

Following [Eltoft,Kim, and Lee 2006b](https://ieeexplore.ieee.org/document/1618702), for covariance with a general Kronecker structure, if each ${\lambda_t}$ has an independent exponential distribution with mean ${\alpha}$, then marginally ${U_t}$ has a multivariate Laplace distribution with mean vector 0 and covariance matrix ${\alpha\Sigma}$.

```{=tex}
\begin{align}
U_t &\sim \text{Laplace}(0, \alpha\Sigma) \\
U_t | \lambda_t &\sim \mathcal{MN}(0, \Sigma, \lambda_t I_T) \\
\lambda_t &\sim \text{Exponential}(\frac{1}{\alpha})
\end{align}
```

The kernel of the likelihood function:

```{=tex}
\begin{align}
L(A,\Sigma,\lambda_t|Y,X) &\propto \det(\Sigma)^{-\frac{T}{2}} \det(\lambda_t I_T)^{-\frac{N}{2}} exp\{-\frac{1}{2} tr[\Sigma^{-1} (Y-XA)' (\lambda_t I_T)^{-1} (Y-XA) ]\}
\end{align}
```

For posteriors distribution, $A$, $\Sigma$ and $\lambda_t$ can then be derived using the likelihood and the prior distributions as follows:

```{=tex}
\begin{align}
p(A,\Sigma|Y,X) &\propto L(A,\Sigma,\lambda_t|Y,X)p(A,\Sigma) \\
\\
&= \det(\Sigma)^{-\frac{T}{2}} \det(\lambda_t I_T)^{-\frac{N}{2}} exp\{-\frac{1}{2} tr[\Sigma^{-1} (Y-XA)' (\lambda_t I_T)^{-1} (Y-XA) ]\} \\
&\times \det(\Sigma)^{-\frac{N+k+\underline{\nu}+1}{2}} exp\{-\frac{1}{2}tr[\Sigma^{-1}(A-\underline{A})'(\underline{V})^{-1}(A-\underline{A})]\} \\
&\times exp\{-\frac{1}{2}tr[\Sigma^{-1}\underline{S}]\} \\
&= \det(\Sigma)^{-\frac{T+N+K+\underline{\nu}+1}{2}} \det(\lambda_t I_T)^{-\frac{N}{2}} \\
&\times exp\{-\frac{1}{2} tr[\Sigma^{-1}(Y'(\lambda_t I_T)^{-1}Y - 2A'X'(\lambda_t I_T)^{-1}Y + A'X'(\lambda_t I_T)^{-1}XA \\
&+ A'\underline{V}^{-1}A -2A'\underline{V}^{-1}\underline{A} + \underline{A}'\underline{V}^{-1}\underline{A} + \underline{S})]\}

\end{align}
```

The kernel can be rearranged in the form of the **Matrix-variate normal-inverse Wishart distribution**.

```{=tex}
\begin{align}
p(A,\Sigma|Y,X) &\sim MNIW(\bar{A},\bar{V},\bar{S},\bar{\nu}) \\
&\\
\bar{V} &= (X'(\lambda_t I_T)^{-1}X + \underline{V}^{-1})^{-1} \\
\bar{A} &= \bar{V}(X'(\lambda_t I_T)^{-1}Y + \underline{V}^{-1}\underline{A}) \\
\bar{\nu} &= T + \underline{\nu}\\
\bar{S} &= Y'(\lambda_t I_T)^{-1}Y + \underline{A}'\underline{V}^{-1}\underline{A} + \underline{S} - \bar{A}'\bar{V}^{-1}\bar{A}
\end{align}
```

The kernel of the fully conditional posterior distribution of $\lambda_t$ is then derived as follows:

```{=tex}
\begin{align}
p(\lambda_t|Y,X,A,\Sigma) &\propto L(A,\Sigma,\lambda_t|Y,X)p(\lambda_t) \\
\\
&\propto \det(\lambda_t I_T)^{-\frac{N}{2}} exp\{-\frac{1}{2} tr[\Sigma^{-1} (Y-XA)' (\lambda_t I_T)^{-1} (Y-XA) ]\} \\
&\times \frac{1}{\alpha}exp\{ -\frac{1}{\alpha}\lambda_t \}\\

&= \lambda_t^{-\frac{TN}{2}} exp\{-\frac{1}{2}\frac{1}{\lambda_t} tr[\Sigma^{-1}(Y-XA)'(Y-XA)]\}\\
&\times exp\{-\frac{1}{\alpha}\lambda_t \}\\

&= \lambda_t^{-\frac{TN}{2}+1-1} exp\{-\frac{1}{2}[\frac{[tr[\Sigma^{-1}(Y-XA)'(Y-XA)]}{\lambda_t} +\frac{2}{\alpha}\lambda_t]\} 
\end{align}
```

The above expression can be rearranged in the form of a Generalized inverse Gaussian distribution kernel as follows:

```{=tex}
\begin{align}
\lambda_t|Y,A,\Sigma &\sim GIG(a,b,p) \\
\\
a &=\frac{2}{\alpha} \\
b &= tr[\Sigma^{-1}(Y-XA)'(Y-XA)] \\
p &= -\frac{TN}{2}+1
\end{align}
```

### Proof of extended model
The Gibbs sampler method will be applied to generate random draws from the full conditional posterior distribution:

1. Draw $\Sigma^{(s)}$ from the $IW(\bar{S},\bar{\nu})$ distribution.
2. Draw $A^{(s)}$ from the $MN(\bar{A},\Sigma^{(s)}, \bar{V})$ distribution.
3. Draw $\lambda_t^{(s)}$ from $GIG(a,b,p)$.

Repeat steps 1, step 2 and 3 for $S_1$+$S_2$times.

Discard the first draws that allowed the algorithm to converge to the stationary posterior distribution.

Output is $\left\{ {A^{(s)}, \Sigma^{(s)}}, \lambda_t^{(s)}\right\}^{S_1+S_2}_{s=S_1+1}$.

```{r Stat Setup for Extend model, fig.align='center',fig.pos='H'}

# setup 
S1                = 500                            # determine the burn-in draws
S2                = 9500                           # number of draws from the final simulation
total_S           = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
lambda.posterior  = matrix(NA, S1+S2, 1)

# initial value of lambda
lambda.posterior[1] = 10                               # set lambda0 

# Prior Gamma distribution: k, theta
lambda.priors = list(
  k = 1,
  theta = .1
)

```

Function below is `posterior.draws.exten`:

```{r Model Exten, fig.align='center',fig.pos='H'}
#| echo: true

## Posterior sample draw function for extended model(posterior.draws.exten)
posterior.draws.exten = function (total_S, Y, X){
for (s in 1:total_S){
    # NIW posterior parameters
    V.bar.inv              = t(X)%*%X + diag(1/diag(lambda.posterior[s]* V.prior)) 
    V.bar                  = solve(V.bar.inv)
    A.bar                  = V.bar%*%(t(X)%*%Y + diag(1/diag(lambda.posterior[s]* V.prior))%*%A.prior)
    nu.bar                 = nrow(Y) + nu.prior
    S.bar                  = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(lambda.posterior[s]* V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv              = solve(S.bar)
  
    # posterior draws for A and Sigma
    Sigma.posterior.IW     = rWishart(1, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior.draw   = apply(Sigma.posterior.IW,3,solve)
    Sigma.posterior[,,s]   = Sigma.posterior.draw
    A.posterior[,,s]       = array(rnorm(prod(c(dim(A.bar),1))),c(dim(A.bar),1))
    L                      = t(chol(V.bar))
    A.posterior[,,s]       = A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    
    
    # Update parameters for lambda posterior
    p                      = lambda.priors$k - (N)/2              # N=10
    diff_A                 = A.posterior[,,s] - A.prior
    product                = t(diff_A) %*% solve(V.prior) %*% diff_A
    b                      = sum(diag(solve(Sigma.posterior[,,s] %*% product)))
    a                      = 2 / lambda.priors$theta
    
    # Draw next period value for lambda from GIG distribution
    if (s!=total_S){
       lambda.posterior[s+1] = GIGrvg::rgig(n=1, lambda = p, chi = b, psi = a)
    }
  }
  
    output                 = list(A.posterior.exten = A.posterior[,,(S1+1):S2], 
                                  Sigma.posterior.exten = Sigma.posterior[,,(S1+1):S2], 
                                  lambda.posterior.exten = lambda.posterior[(S1+1):S2,])

    return(output)
}
```

#### Function Proofing

```{r Extend Model Function Proof, fig.align='center',fig.pos='H'}

# setup 
kappa.1           = 1                                # shrinkage for A1 to Ap
kappa.2           = 100                              # shrinkage for constant 
S1                = 500                              # determine the burn-in draws
S2                = 9500                             # number of draws from the final simulation
total_S           = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
k.posterior       = matrix(NA, S1+S2, 1)
k.posterior[1]    = 10                               # set k0 

# Prior Gamma distribution: k, theta
lambda.priors = list(
  k = 1,
  theta = .1
)

# Applying function 
posterior.extend.draws.p = posterior.draws.exten(total_S = total_S, Y=Y, X=X)
```

After fitting a model that includes a constant term and one lag with artificial data, just like the basic model, the extend model also shows that the posterior mean of both the autoregressive and covariance matrices closely identity matrix, and the posterior mean of the constant term is almost a vector of zeros.

 - The posterior mean of the $A$ is:

```{r Extend Model Proof A, fig.align='center',fig.pos='H'}

extend.model.proof.A <-
  tibble( "A" = c("Constant term", "Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.extend.draws.p[["A.posterior.exten"]][1,1,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][2,1,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][3,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.extend.draws.p[["A.posterior.exten"]][1,2,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][2,2,]),4),
              round(mean(posterior.extend.draws.p[["A.posterior.exten"]][3,2,]),4))
  )

kable(extend.model.proof.A, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 4 Extend Model Proofing Simulation for $A$


 - The posterior mean of the $\Sigma$ is:

```{r Extend Model Proof Sigma, fig.align='center',fig.pos='H'}

extend.model.proof.Sigma <-
  tibble( "Sigma" = c("Y1 lag","Y2 lag"),
          "Simulation Parameter Y1" 
          = c(round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][1,1,]),4),
              round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][2,1,]),4)),
           "Simulation Parameter Y2" 
          = c(round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][1,2,]),4),
              round(mean(posterior.extend.draws.p[["Sigma.posterior.exten"]][2,2,]),4))
  )

kable(extend.model.proof.Sigma, align = "c") %>% 
  kable_styling(font_size = 8, 
                fixed_thead = TRUE, 
                full_width = FALSE, 
                position = "center",
                latex_options = c("HOLD_position"),
                bootstrap_options = c("striped", "hover", "bordered", "responsive", "dark"))

```

Table 5 Extend Model Proofing Simulation for $\Sigma$



# References {.unnumbered}
